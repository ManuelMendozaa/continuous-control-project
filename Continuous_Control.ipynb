{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtensorflow 1.7.1 has requirement numpy>=1.13.3, but you'll have numpy 1.12.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 3.0.30 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mjupyter-console 6.4.3 has requirement jupyter-client>=7.0.0, but you'll have jupyter-client 5.2.4 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environments corresponding to both versions of the environment are already saved in the Workspace and can be accessed at the file paths provided below.  \n",
    "\n",
    "Please select one of the two options below for loading the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "# select this option to load version 1 (with a single agent) of the environment\n",
    "# env = UnityEnvironment(file_name='/data/Reacher_One_Linux_NoVis/Reacher_One_Linux_NoVis.x86_64')\n",
    "\n",
    "# select this option to load version 2 (with 20 agents) of the environment\n",
    "env = UnityEnvironment(file_name='/data/Reacher_Linux_NoVis/Reacher.x86_64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "   1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   5.75471878e+00  -1.00000000e+00\n",
      "   5.55726624e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "  -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Note that **in this coding environment, you will not be able to watch the agents while they are training**, and you should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 0.18749999580904841\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name]      # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  A few **important notes**:\n",
    "- When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```\n",
    "- To structure your work, you're welcome to work directly in this Jupyter notebook, or you might like to start over with a new file!  You can see the list of files in the workspace by clicking on **_Jupyter_** in the top left corner of the notebook.\n",
    "- In this coding environment, you will not be able to watch the agents while they are training.  However, **_after training the agents_**, you can download the saved model weights to watch the agents on your own machine! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "from workspace_utils import active_session\n",
    "\n",
    "# Import agent\n",
    "from agent import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agent(n_episodes=500, max_t=1000, solved_score=30.0, consec_episodes=100, print_every=1, train_mode=True):\n",
    "    scores_list = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)       # last 100 scores\n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        # Reset environment\n",
    "        env_info = env.reset(train_mode=train_mode)[brain_name]\n",
    "        # Extract initial state\n",
    "        states = env_info.vector_observations     \n",
    "        # Prepare scores vector\n",
    "        scores = np.zeros(num_agents)\n",
    "        # Reset agent's noise\n",
    "        agent.reset()\n",
    "\n",
    "        for t in range(max_t):\n",
    "            # Select agent's action\n",
    "            actions = agent.act(states)\n",
    "            # Send action to the environment\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            # Get state update\n",
    "            next_states = env_info.vector_observations\n",
    "            # Get action reward\n",
    "            rewards = env_info.rewards\n",
    "            # Check if episode has concluded\n",
    "            dones = env_info.local_done\n",
    "            \n",
    "            # Save tuples in buffer\n",
    "            for state, action, reward, next_state, done in zip(states, actions, rewards, next_states, dones):\n",
    "                agent.step(state, action, reward, next_state, done, t)\n",
    "            \n",
    "            # Update episode's state and scores\n",
    "            states = next_states\n",
    "            scores += rewards\n",
    "            \n",
    "            # Exit loop if episode has concluded\n",
    "            if np.any(dones): break\n",
    "\n",
    "\n",
    "        # Save scores\n",
    "        scores_window.append(np.mean(scores))\n",
    "        scores_list.append(np.mean(scores))\n",
    "        \n",
    "        # Visualization\n",
    "        print('\\rEpisode {}\\tMean Score: {:.2f}'.format(i_episode, scores_window[-1], end=\"\"))\n",
    "        if i_episode % 10 == 0:\n",
    "            print('\\nEpisode {}\\tMean Score: {:.2f}'.format(i_episode, scores_window[-1], end=\"\"))\n",
    "                  \n",
    "        if np.mean(scores_window) >= 30 and i_episode > 100:\n",
    "            print('\\nEnvironment solved in {: d} episodes!\\tMean Score: {: .3f}'.format(i_episode - 100, scores_window[-1]))\n",
    "            torch.save(agent._actor_local.state_dict(), 'actor_weights.pth')\n",
    "            torch.save(agent._critic_local.state_dict(), 'critic_weights.pth')\n",
    "            break\n",
    "            \n",
    "    return scores_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    fig = plt.figure()\n",
    "    plt.plot(np.arange(len(results)), results)\n",
    "    plt.ylabel('Score')\n",
    "    plt.xlabel('Episode #')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\tMean Score: 0.09\n",
      "Episode 2\tMean Score: 0.56\n",
      "Episode 3\tMean Score: 1.05\n",
      "Episode 4\tMean Score: 0.79\n",
      "Episode 5\tMean Score: 0.91\n",
      "Episode 6\tMean Score: 1.16\n",
      "Episode 7\tMean Score: 2.02\n",
      "Episode 8\tMean Score: 1.98\n",
      "Episode 9\tMean Score: 2.44\n",
      "Episode 10\tMean Score: 2.56\n",
      "\n",
      "Episode 10\tMean Score: 2.56\n",
      "Episode 11\tMean Score: 3.24\n",
      "Episode 12\tMean Score: 3.84\n",
      "Episode 13\tMean Score: 4.25\n",
      "Episode 14\tMean Score: 3.90\n",
      "Episode 15\tMean Score: 4.62\n",
      "Episode 16\tMean Score: 6.36\n",
      "Episode 17\tMean Score: 7.48\n",
      "Episode 18\tMean Score: 8.55\n",
      "Episode 19\tMean Score: 8.97\n",
      "Episode 20\tMean Score: 11.94\n",
      "\n",
      "Episode 20\tMean Score: 11.94\n",
      "Episode 21\tMean Score: 11.03\n",
      "Episode 22\tMean Score: 12.61\n",
      "Episode 23\tMean Score: 13.21\n",
      "Episode 24\tMean Score: 13.78\n",
      "Episode 25\tMean Score: 14.06\n",
      "Episode 26\tMean Score: 14.52\n",
      "Episode 27\tMean Score: 17.29\n",
      "Episode 28\tMean Score: 16.75\n",
      "Episode 29\tMean Score: 15.98\n",
      "Episode 30\tMean Score: 16.89\n",
      "\n",
      "Episode 30\tMean Score: 16.89\n",
      "Episode 31\tMean Score: 18.43\n",
      "Episode 32\tMean Score: 21.19\n",
      "Episode 33\tMean Score: 20.00\n",
      "Episode 34\tMean Score: 21.25\n",
      "Episode 35\tMean Score: 20.79\n",
      "Episode 36\tMean Score: 22.46\n",
      "Episode 37\tMean Score: 24.42\n",
      "Episode 38\tMean Score: 25.73\n",
      "Episode 39\tMean Score: 26.94\n",
      "Episode 40\tMean Score: 29.07\n",
      "\n",
      "Episode 40\tMean Score: 29.07\n",
      "Episode 41\tMean Score: 28.45\n",
      "Episode 42\tMean Score: 32.74\n",
      "Episode 43\tMean Score: 31.24\n",
      "Episode 44\tMean Score: 32.94\n",
      "Episode 45\tMean Score: 32.10\n",
      "Episode 46\tMean Score: 34.02\n",
      "Episode 47\tMean Score: 33.16\n",
      "Episode 48\tMean Score: 33.85\n",
      "Episode 49\tMean Score: 35.50\n",
      "Episode 50\tMean Score: 36.68\n",
      "\n",
      "Episode 50\tMean Score: 36.68\n",
      "Episode 51\tMean Score: 37.25\n",
      "Episode 52\tMean Score: 36.31\n",
      "Episode 53\tMean Score: 34.15\n",
      "Episode 54\tMean Score: 36.88\n",
      "Episode 55\tMean Score: 37.73\n",
      "Episode 56\tMean Score: 38.13\n",
      "Episode 57\tMean Score: 37.92\n",
      "Episode 58\tMean Score: 38.16\n",
      "Episode 59\tMean Score: 37.77\n",
      "Episode 60\tMean Score: 37.62\n",
      "\n",
      "Episode 60\tMean Score: 37.62\n",
      "Episode 61\tMean Score: 38.35\n",
      "Episode 62\tMean Score: 38.21\n",
      "Episode 63\tMean Score: 37.78\n",
      "Episode 64\tMean Score: 38.72\n",
      "Episode 65\tMean Score: 37.37\n",
      "Episode 66\tMean Score: 38.04\n",
      "Episode 67\tMean Score: 38.41\n",
      "Episode 68\tMean Score: 38.64\n",
      "Episode 69\tMean Score: 38.55\n",
      "Episode 70\tMean Score: 39.20\n",
      "\n",
      "Episode 70\tMean Score: 39.20\n",
      "Episode 71\tMean Score: 38.80\n",
      "Episode 72\tMean Score: 39.25\n",
      "Episode 73\tMean Score: 39.18\n",
      "Episode 74\tMean Score: 39.31\n",
      "Episode 75\tMean Score: 39.32\n",
      "Episode 76\tMean Score: 39.19\n",
      "Episode 77\tMean Score: 39.33\n",
      "Episode 78\tMean Score: 38.70\n",
      "Episode 79\tMean Score: 38.61\n",
      "Episode 80\tMean Score: 38.47\n",
      "\n",
      "Episode 80\tMean Score: 38.47\n",
      "Episode 81\tMean Score: 38.28\n",
      "Episode 82\tMean Score: 38.59\n",
      "Episode 83\tMean Score: 39.29\n",
      "Episode 84\tMean Score: 38.75\n",
      "Episode 85\tMean Score: 38.79\n",
      "Episode 86\tMean Score: 38.78\n",
      "Episode 87\tMean Score: 39.27\n",
      "Episode 88\tMean Score: 38.96\n",
      "Episode 89\tMean Score: 38.80\n",
      "Episode 90\tMean Score: 38.92\n",
      "\n",
      "Episode 90\tMean Score: 38.92\n",
      "Episode 91\tMean Score: 38.90\n",
      "Episode 92\tMean Score: 37.43\n",
      "Episode 93\tMean Score: 38.82\n",
      "Episode 94\tMean Score: 38.86\n",
      "Episode 95\tMean Score: 36.99\n",
      "Episode 96\tMean Score: 37.82\n",
      "Episode 97\tMean Score: 38.30\n",
      "Episode 98\tMean Score: 38.00\n",
      "Episode 99\tMean Score: 37.21\n",
      "Episode 100\tMean Score: 37.01\n",
      "\n",
      "Episode 100\tMean Score: 37.01\n",
      "Episode 101\tMean Score: 35.42\n",
      "Episode 102\tMean Score: 38.02\n",
      "Episode 103\tMean Score: 38.31\n",
      "Episode 104\tMean Score: 37.13\n",
      "Episode 105\tMean Score: 37.03\n",
      "Episode 106\tMean Score: 38.69\n",
      "Episode 107\tMean Score: 36.94\n",
      "Episode 108\tMean Score: 37.91\n",
      "Episode 109\tMean Score: 37.34\n",
      "\n",
      "Environment solved in  9 episodes!\tMean Score:  37.336\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(state_size, action_size, device=device)\n",
    "\n",
    "with active_session():\n",
    "    scores = train_agent(n_episodes=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Environment solved in  9 episodes!\tMean Score:  30.227\n"
     ]
    }
   ],
   "source": [
    "print('\\nEnvironment solved in {: d} episodes!\\tMean Score: {: .3f}'.format(9, np.mean(scores[9:109])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2fca3b6d30>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_results(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
